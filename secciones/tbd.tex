\chapter{Esquema de Detección}\label{chap:tbd}

Las imágenes satelitales son una fuente de información utilizadas cada vez más en la actualidad por diferentes campos de la ciencia, a través de una imagen satelital podemos extraer información que permiten estudiar diferentes características de los suelos, obtener información de fenómenos naturales y ayudar a las toma de decisiones (sec. \ref{sec:estadodelarte}). Una cámara a bordo de un satélite además nos da la posibilidad de ayudar a la toma de decisiones logrando que de manera automática pueda por ejemplo trazar el curso del satélite previniendo coaliciones o como un mecanismo de ayuda para calibrar su apuntamiento (sec. \ref{sec:fundamentacion}) brindando más autonomía en la navegación y en la toma de decisiones. 

Como ya se mencionó anteriormente en el  capitulo \ref{chap:introduccion} el objetivo de este trabajo de investigación  (sec. \ref{sec:obj_general}) es realizar una evaluación experimental de factibilidad en utilizar algoritmos de aprendizaje automático para  la detección de patrones de interés de la misión \ac{fs} (sec. \ref{sec:contexto})  brindando una  fuente extra de información al satélite para la toma de decisiones de manera automática. 

Los algoritmos de aprendizaje automático como se desarrolló en capítulos anteriores (sec. \ref{sec:machinelaerning}) tienen la capacidad de generalizar (aprender)  a partir de los datos, estos datos son los que llamamos conjunto de entrenamiento, para entrenar un modelo de aprendizaje automático necesitamos además del conjunto de datos mencionados previamente definir una función de costo (sec. \ref{sub:funcion_costo}) que nos aproxime a los valores de la salida que estamos esperando y un algoritmo de clasificación (sec. \ref{sub:clasificadores}) que nos indique a qué clase o categoría pertenece cada valor. 

En el desarrollo de este trabajó no solo se preciso realizar el entrenamiento de los datos sino además se necesito extraer la información de la imagen. Para poder extraer la información de las imágenes utilizamos las redes convolucionales (sec. \ref{sec:compueter-vision}), estas redes son un tipo de modelos de redes neuronales que nos permiten extraer patrones (características) de una imagen como el color, la forma, los bordes por medio de la operación de convolución (sec. \ref{sub:convolucion}); las operaciones de convolución son operaciones de producto y sumas entre las diferentes capas y filtros de la red que generan como salida un mapa de característica que representa a la imagen. Existen en la actualidad diferentes arquitecturas de redes convolucionales cómo se desarrolló en la sección (sec. \ref{sub:arquitecturacnn}), mas adelante  detallaremos el tipo de arquitectura de red convolucional utilizada para este trabajo.

Uno de los problemas que se presentan a la hora de desarrollar un detector de patrones además de la extracción de la información de la imagen es determinar en qué posición se encuentra el objeto de interés que deseamos reconocer esto se lo conoce en la literatura como el \textit{problema de la detección} (sec. \ref{sub:problema_deteccion}), existen diferentes técnicas que nos ayudan a resolver este problema; estas técnicas son conocidas como regiones propuestas (sec. \ref{sub:regions-proposal}). Los métodos de regiones propuestas extraen y agrupan información de la imagen con similares característica, estos tipos de métodos generan un conjunto de regiones candidatas con una probabilidad en cada región generada que nos indica con qué posibilidad pueda ser encontrado el objeto que estamos buscando en la imagen; cada región luego será utilizada como conjunto de entrenamiento con algunos de los algoritmos de clasificación nombrado anteriormente. La salida de este esquema de procesamiento será un modelo que permita detectar a qué clase pertenece un nuevo dato nunca visto.

En este capítulo vamos a desarrollar el esquema de trabajo utilizado para la creación de un modelo de aprendizaje automático que permita detectar las zonas de interés como se expuso en la sección (sec. \ref{sub:obj_especifico}). Además se describirán las diferentes metodologías y decisiones tomadas en la construcción de la solución como son las herramientas utilizadas, el etiquetado de los datos de entrenamiento, los diferentes  métodos de regiones propuestas utilizados, la arquitectura seleccionada para la extracción de las características de la imagen y por último el proceso de clasificación y validación del modelo entrenado.




%En este capítulo vamos a detallar las decisiones tomadas en la selección de determinados métodos expuesto en el capítulo anterior, las  herramientas utilizadas y el tipo de arquitectura seleccionada para la extracción de los datos, es decir, se desarrollara el pipeline utilizado para la construcción de la solución.
%


\section{Esquema de procesamiento}\label{sec: pipeline}

%En la siguiente imagen \ref{Fig:pipeline} podemos ver un pipeline de desarrollo en aprendizaje supervisado:
%\begin{figure}[H] \centering
%  \includegraphics[height=8cm,keepaspectratio=true,clip=true]{imagenes/tbd/pipeline-sp.png}
%  \caption{Pipeline}\label{Fig:pipeline}
%\end{figure}
Partiendo de lo desarrollado anteriormente, en esta sección vamos a entrar desarrollar el esquema de trabajo planteado para la solución del problema. En la siguiente figura \ref{Fig:pipeline-mio} se puede visualizar el \textit{pipeline} de trabajo propuesto que incluye desde la captura y recopilación de los datos hasta la predicción final de una imagen.

\begin{figure}[H] \centering
  \includegraphics[height=10cm,keepaspectratio=true,clip=true]{imagenes/tbd/pipeline_mio.png}
  \caption{Pipeline de Trabajo}\label{Fig:pipeline-mio}
\end{figure}

\newpage
%https://www.datanami.com/2018/09/05/how-to-build-a-better-machine-learning-pipeline/
\subsection*{Descripción del pipeline desarrollado}\label{sub:desc-pipeline}

En la primera etapa del pipeline de desarrollo se basó en la obtención y recolección de datos provenientes del satélite (también llamado datos \textit{raw}); en esta etapa se recolectaron todos los datos que serán usado para entrenar y validar el modelo. Este proceso abarca desde la descarga de los datos por medio de la página oficial de \ac{conae} hasta el almacenado de los mismos, en el sección \ref{sec:recoleccion} se desarrolla con más detalle los pasos que se realizaron para la obtención y descarga de los datos.

A partir de los datos descargados  se debe realizar el procesamiento de los mismos para poder utilizarlo, este procesamiento se basa en convertir los datos proveniente de los satélites en imágenes RGB. El el proceso de conversión a imágenes RGB se realizó a través de la herramienta \textit{ENVI}, esta herramienta es un software  especializado en el procesamiento y análisis de imágenes  geoespaciales. Debido a la característica que posee el sensor que utilizamos en el desarrollo \textit{VIIRS}, se descompone en diferentes bandas en el espectro electromagnético de las cuales seis bandas son relacionadas en el espectro visible (\textit{VIS}), cuatro en el infrarrojo cercano (\textit{NIR} por sus siglas en inglés), cuatro en el infrarrojo de onda corta (\textit{SWIR}), tres en el infrarrojo medio (\textit{MIR}) y cuatro en el infrarrojo térmico (\textit{TIR}). Para la construcción del set de datos final se usaron diferentes combinaciones de bandas (sec. \ref{sub:comb_de_banda}), cada una de las bandas deben ser cargadas al software \textit{ENVI} que luego se combinarán cada uno de los diversos canales \textit{RGB} para la construcción de la misma. Luego de este proceso obtenemos la imagen final como se puede visualizar en la figura \ref{Fig:img-final}. En la sección \ref{sec:recoleccion} se desarrolla de manera más detallada que bandas fueron utilizadas y el proceso que se llevó a cabo para la conversión de datos.

\begin{figure}[H] \centering
  \includegraphics[scale=0.4,keepaspectratio=true,clip=true]{imagenes/tbd/pre-img.png}
  \caption{Imagen final obtenida luego del procesamiento.}\label{Fig:img-final}
\end{figure}


Una vez obtenida las imágenes se generó regiones candidatas a través de métodos de regiones propuestas (sec. \ref{sub:regions-proposal}) como se puede visualizar en la siguiente imagen \ref{Fig:rp-ejemplo}, estos métodos nos retorna  un conjunto de bounding boxes.

\begin{figure}[H] \centering
  \includegraphics[scale=0.25,keepaspectratio=true,clip=true]{imagenes/tbd/proposal-img.png}
  \caption{Ejemplo regions proposal aplicado a una imagen satelital.}\label{Fig:rp-ejemplo}
\end{figure}

En base a los diferentes métodos desarrollados en la sección (sec. \ref{sub:regions-proposal}) se realizó una evaluación empírica de los mismos con el fin de seleccionar uno para las correspondientes pruebas. Para dar mas detalle de la evaluación realizada podemos ver la siguiente tabla \ref{tabla:comparacionregiones}:

\begin{table}[H]\centering
\begin{tabular}{|p{2cm}|p{6cm}|p{8cm}|}
    \hline 
     \centering \textbf{Método}  & \centering \textbf{Ventajas} & \multicolumn{1}{c|}{\centering \textbf{Desventajas}} \\
    \hline
    \centering Selective Search \ref{sub:regions-proposal} & \parbox[p][0.2\textwidth][c]{6cm}{
    \begin{itemize}
        \item Modela la probabilidad de que exista un objeto en la región encontrada.
        \item Diferentes escalas de detección.
        \item Se puede configurar el tamaño de cada región.
    \end{itemize}}  &  \parbox[p][0.2\textwidth][c]{7.5cm}{
    \begin{itemize}
        \item Tiempo de ejecución muy alto para imágenes de resolución mayores; ejemplo: 2800x3000px.	
    \end{itemize} } \\ \hline
    \centering Edges Boxes \ref{sub:regions-proposal} & \parbox[p][0.2\textwidth][c]{6cm}{
    \begin{itemize}
        \item Buen tiempo de ejecución con imágenes de gran tamaño
        \item Reconocimientos de regiones de menor tamaño
        \item Nos da la probabilidad de que la región contenga un objeto.
    \end{itemize} } & \parbox[p][0.2\textwidth][c]{7.5cm}{
    \begin{itemize}
        \item No segmenta las regiones, por lo que pierde precisión en relación a métodos como selective search.
    \end{itemize} } \\ \hline 
     \centering BING & \parbox[p][0.2\textwidth][c]{6cm}{
    \begin{itemize}
        \item Tiempo de ejecución.
    \end{itemize} } &  \parbox[p][0.2\textwidth][c]{7.5cm}{
    \begin{itemize}
        \item No encuentra regiones cuando las imágenes son grandes.
        \item No se puede customizar el tamaño de la ventana
    \end{itemize} } \\ \hline
\end{tabular}
\caption{Análisis de métodos Regiones Propuestas}
\label{tabla:comparacionregiones}
\end{table}

Obtenido el conjunto de regiones candidatas por cada una de las imágenes se aplicó \ac{nms} (sec. \ref{sub:nonmaximumsuppression}) para descartar regiones solapadas. El nivel de solapamiento entre regiones se calcula obteniendo la intersección sobre la unión de dos regiones, este valor nos indica en porcentaje el nivel de solapamiento entre estas. En esta tesis se utilizó un umbral de $80%$ para aquellas regiones que tengan un solapamiento mayor al umbral. El proceso descrito se realizó para cada una de las imágenes del conjunto de datos descargado.

Luego del proceso de \ac{nms} para cada región obtenida se debe extraer la información de cada una de las imágenes. Las redes neuronales convolucionales (sec. \ref{sub:cnn}), permiten extraer las característica distintiva de la imagen haciendo uso de operaciones de convolución como se desarrolló en el capítulo (sec. \ref{sub:cnn}). El proceso de extracción de información consta como primer paso seleccionar el tipo de arquitectura de la red que será utilizada, para esta tesis se trabajó con la arquitectura de red \textit{ResNet50} (sec. \ref{sub:arquitecturacnn}); la arquitectura  resnet50 recibe como input una imagen de $224 x 224$ y nos retorna un vector de $2048$ dimensiones que será nuestra información para el entrenamiento del modelo.
Como paso siguiente luego de la selección de la arquitectura se debe normalizar las imágenes al tamaño requerido por la red; esta imagen normalizada será convertida a un vector que pasará por cada una de las capas de la red para luego ser extraída de la ante ultima capa que será la que contenga la información final de la imagen, este proceso se debe realizar para cada uno de los bounding boxes contenidos en la imagen. El proceso de entrenamiento comienza luego de obtener el conjunto de datos etiquetado (sec. \ref{sub:generacion_datos_etiquetado}), para luego realizar los diferentes experimentos con los datos anotados como selección del modelo y búsqueda de hiper-parámetros.

La etapa de validación de los datos se realizó con el conjunto de datos de test, se calculó las métricas de precisión, recall, curvas roc y average precisión (medida de detección) (sec. \ref{sub:evaluación-modelo}) para determinar la eficiencia de los  modelos entrenados en el paso anterior. Luego de diversas iteraciones se llegó a un modelo que maximicen estas métricas mencionadas, este modelo será la versión final que será utilizado para realizar la predicción de datos que nunca vio el modelo.

La predicción del modelo final tendrá como respuesta un conjunto de regiones (x, y, w, h) de la imagen nueva de entrada en el cual cada una de estas regiones está asociada una respuesta que nos indica con los valor "0" si la región de interés no contiene el objeto de interés, en caso contrario  retorna "1"; cada una de esta predicciones está asociada a un valor de probabilidad que indica cuán posible es que la región de interés buscada esté en esa imagen.

\section{Recolección de datos}\label{sec:recoleccion}

En esta sección se describe cuáles fueron los pasos que se llevaron a cabo para obtener el conjunto de imágenes de entrenamiento y validación; se describe de manera más detallada cómo se obtuvieron los conjunto de datos y que configuraciones de bandas se utilizaron para la construcción de las imágenes.


\subsection{Imágenes satelitales}\label{sub:nivelesdeprocesamiento}

Una imagen satelital se la puede definir como la representación visual de información capturada por un sensor montado en un satélite artificial (sec. \ref{sub:imagen_satelital}). Estos sensores recogen la información reflejada por la superficie de la tierra que luego es enviada para su posterior procesamiento. El uso de imágenes satelitales constituye una excelente herramienta para el conocimiento y monitoreo de los territorios y recursos; hoy en día disfrutamos de la oportunidad de aprovechar estas imágenes satelitales para una gran variedad de aplicaciones como: desarrollo y planificación urbana, infraestructura, recursos naturales, investigación, alerta temprana de catástrofes, asuntos militares, entre otras.

Una imagen satelital debe pasar por diferentes niveles de procesamiento dependiendo el tipo de uso que se le quiera dar. En el campo de la teledetección (sec. \ref{sub:teledeteccion}) cuando hablamos de niveles de procesamiento nos referimos a los diversos procesos que son aplicados a una imagen satelital, dependiendo de la agencia espacial existe una nomenclatura para determinar qué niveles de procesamiento fueron aplicados. En este trabajo se utilizó la nomenclatura propuesta por \ac{nasa}:
\begin{itemize}
	\item \textbf{Nivel 0}: La información científica recogida está a máxima resolución, ordenada temporalmente y con errores de transmisión, artefactos y duplicados eliminados.
 	\item \textbf{Nivel 1a}: La información está ordenada cronológicamente y datos auxiliares como coeficientes de calibración y parámetros de referencia.
 	\item \textbf{Nivel 1b}: La información del 1a es procesada a unidades de detección, geo-refereciada.
 	\item \textbf{Nivel 2}: Variables geofísicas derivadas por ejemplo productos de concentraciones de hielo, ola de mar, etc.
 	\item \textbf{Nivel 3}: Las variables son mapeadas uniformemente en \textit{grids} espacio-temporales.
 	\item \textbf{Nivel 4}: Resultados de los análisis de los niveles anteriores
\end{itemize}

Las imagenes utilizadas para el desarrollo de los experimentos fueron descargadas por medio del catálogo  publicado en el sitio oficial de \ac{conae} \footnote{Fuente: http://catalogos.conae.gov.ar/catalogo/catalogo-de-imagenes.html} de acceso gratuito para el público. Se debe señalar además que se trabajó con imágenes correspondiente a los años 2017 y 2018 con una ventana de tiempo desde Abril del 2017 a Marzo del 2018; estas imágenes son de naturaleza óptica con un nivel de procesamiento \textbf{1a}, de acuerdo a las nomenclaturas utilizadas por \ac{nasa}.

De acuerdo a las característica del proyecto y tomando como fundamentación lo expuesto en la sección (sec. \ref{sec:fundamentacion}), se utilizaron imágenes que se asemejan a las características del \ac{fs} \ac{conae} detalladas en los requerimientos formales del mismo, estas imágenes fueron adquiridas por el instrumento \ac{viirs}. El instrumento \ac{viirs} fue lanzado a bordo del satélite Suomi-NPP el 28 de octubre de 2011; posee 5 canales de alta resolución (I-bands), 16 canales de resolución moderada (M-bands) y un canal de baja luz (Day/Night Band, DNB).  

En el siguiente cuadro se detallan las diferentes longitudes de onda y los rangos de onda de las bandas, junto con resolución geométrica apuntando a Nadir (tabla. \ref{tab:viirs}).
\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c||c|c|c|}
\hline \textbf{Banda} & Rango Espectral (um) & Resolución Nadir & \textbf{Banda} & Rango Espectral (um) & Resolución Nadir \\\hline 
 		M1  & 0.402-0.422   & 0.742 x 0.259 & I3  & 1.580-1.640   & 0.371 x 0.387 \\ \hline 
		M2  & 0.436-0.454   & 0.742 x 0.259 & M10 & 1.580-1.640   & 0.742 x 0.776 \\ \hline 
		M3  & 0.478-0.498   & 0.742 x 0.259 & M11 & 2.225-2.275   & 0.742 x 0.776 \\ \hline 
		M4  & 0.545-0.565   & 0.742 x 0.259 & I4  & 3.550-3.930   & 0.371 x 0.387 \\ \hline 
		I1  & 0.600-0.680   & 0.371 x 0.387 & M12 & 3.660-3.840   & 0.742 x 0.776 \\ \hline 
		M5  & 0.662-0.682   & 0.742 x 0.259 & M13 & 3.973-4.128   & 0.742 x 0.259 \\ \hline 
		M6  & 0.739-0.754   & 0.742 x 0.776 & M14 & 8.400-8.700   & 0.742 x 0.776 \\ \hline 
		I2  & 0.846-0.885   & 0.371 x 0.387 & M15 & 10.263-11.263 & 0.742 x 0.776 \\ \hline 
		M7  & 0.846-0.885   & 0.742 x 0.259 & I5  & 10.500-12.400 & 0.371 x 0.387 \\ \hline 
		M8  & 1.230-1.250   & 0.742 x 0.776 & M16 & 11.538-12.488 & 0.742 x 0.776 \\ \hline 
		M9  & 1.371-1.386   & 0.742 x 0.776 & - &-&- \\ \hline 
\end{tabular}
\end{center}\caption{Característica de bandas,\ac{viirs} \label{tab:viirs}}
\end{table}

\subsection{Generación de datos etiquetados}\label{sub:generacion_datos_etiquetado}

Para entrenar un algoritmo de aprendizaje supervisado debemos tener datos con las etiqueta por cada región que queremos aprender. Crear un conjunto de datos etiquetados consiste en poder identificar qué regiones son de interés para nuestro problema, \textit{ground truth}, y etiquetarlo. En esta tesis las regiones de interés son el \textit{Golfo de San Matías} y  \textit{Laguna de Mar Chiquita} como se mencionó en la sección (sec.  \ref{sec:obj_general}).

El etiquetado de las regiones se realizó utilizando la librería \textit{Labelme} \footnote{Funte: https://github.com/wkentaro/labelme} 
}, en donde se marcó con polígonos las regiones de nuestro conjunto de entrenamiento, cabe aclarar que se podría haber utilizado bounding boxes para etiquetar la región pero para tener una mayor precisión en el etiquetado de la región se optó por utilizar polígonos, en la imagen \ref{Fig:labelme-etiquetado} se puede visualizar el proceso. Cada región etiquetada por imagen será almacenada en un format  \textit{json} para luego ser re-utilizada para el cálculo de regiones propuestas.

El proceso siguiente al proceso de etiquetado del ground truth es poder generar un conjunto de datos finales para el entrenamiento y validación de los modelos. Este proceso consiste en calcular por algún método de regiones propuesta regiones candidatas en donde por cada región candidata se obtiene el nivel de solapamiento entre la región obtenida y el dato que se etiqueto como ground truth. El cálculo de solapamiento se realiza obteniendo el valor IoU, intersección sobre unión; si el valor de IoU supera un valor de umbral definido previamente la región obtenida será etiquetada como región positiva en caso contrario s	erá clasificada como región negativa. Este proceso se debe realizar por cada una de las imágenes.


Ya con los datos generados y etiquetados se debe calcular los vectores de características de cada región, estos vectores lo obtenemos a través de una red neuronal. Una vez realizado todo el proceso de etiquetado, extracción de datos y obtención del vector de característica tenemos nuestro conjunto de datos que será con el que comenzaremos el proceso de entrenamiento.



\begin{figure}[H] \centering
  \includegraphics[scale=0.2,keepaspectratio=true,clip=true]{imagenes/tbd/labelme1.png}
  \caption{Region de interes etiquetada.}\label{Fig:labelme-etiquetado}
\end{figure}

